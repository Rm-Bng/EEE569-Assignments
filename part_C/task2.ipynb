{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7383934c-e2b4-4689-b3d3-9f6e9ba27cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22929ae2-d29e-4e94-9df5-314d193b1127",
   "metadata": {},
   "source": [
    "# Max Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cfb25a-4402-4a7f-80c3-5d29b48ff6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpooling(array, pool_size, stride, comming_gradient):\n",
    "    b,hi,wi,c = array.shape\n",
    "    ho = int((hi-pool_size)/stride) + 1\n",
    "    wo = int((wi-pool_size)/stride) + 1\n",
    "    output_shape = (b,ho,wo,c)\n",
    "    output = np.zeros(output_shape)\n",
    "    \n",
    "    \n",
    "    #forward\n",
    "    for i in range (ho):\n",
    "        hstart = i * stride\n",
    "        hend =  hstart + pool_size\n",
    "        for j in range (wo):\n",
    "            vstart = j * stride\n",
    "            vend =  vstart + pool_size\n",
    "            \n",
    "            window = array[:,hstart:hend, vstart:vend,:]\n",
    "            output[:,i,j,:] = np.max(window,axis=(1, 2))\n",
    "\n",
    "    #backward\n",
    "    gradient = np.zeros(array.shape)#gradients have the same size of inputs\n",
    "    b,hg,wg,c = comming_gradient.shape\n",
    "    \n",
    "    for i in range (hg):\n",
    "        hstart = i * stride\n",
    "        hend =  hstart + pool_size\n",
    "        \n",
    "        for j in range (wg):\n",
    "            vstart = j * stride\n",
    "            vend =  vstart + pool_size\n",
    "            \n",
    "            window = array[:,hstart:hend, vstart:vend,:]\n",
    "            x = np.max(window,axis=(1, 2)).reshape(b,1,1,c)\n",
    "            \n",
    "            window = ( window == x )\n",
    "            k = comming_gradient[:, i, j, :].reshape(b,1,1,c)\n",
    "            \n",
    "            gradient[:,hstart:hend, vstart:vend,:] = window * k\n",
    "    \n",
    "    return output, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbfdcd9-f5dc-4031-8689-20eb3c9911fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.array([[[[23, 95],[92, 43],[28,  2],[51, 89]],\n",
    "                          [[30, 95],[98, 77],[69, 42],[ 2,  6]],\n",
    "                          [[16, 75],[28, 11],[ 2, 86],[66, 17]],\n",
    "                          [[34, 22],[74, 26],[68, 38],[83,  8]]],\n",
    "                         \n",
    "                         [[[83, 95],[15, 28],[60, 47],[42, 43]],\n",
    "                          [[73, 94],[70, 44],[34, 56],[42, 29]],\n",
    "                          [[54, 75],[82, 35],[25, 78],[77, 43]],\n",
    "                          [[ 2, 82],[19, 16],[44, 21],[67, 33]]],\n",
    "                         \n",
    "                         [[[67, 32],[ 4, 60],[70,  8],[48, 57]],\n",
    "                          [[ 3, 91],[33,  1],[53, 65],[17, 92]],\n",
    "                          [[22, 60],[91, 57],[86, 87],[42, 35]],\n",
    "                          [[56, 57],[20, 80],[90, 34],[99, 91]]]]) #shape (3,4,4,2)\n",
    "\n",
    " \n",
    "\n",
    "comming_gradient = np.array([[[[1, 1],[1, 1]],\n",
    "                              [[1, 1],[1, 1]]],\n",
    "                              \n",
    "                             [[[1, 1],[1, 1]],\n",
    "                              [[1, 1],[1, 1]]],\n",
    "                                                            \n",
    "                             [[[1, 1],[1, 1]],\n",
    "                              [[1, 1],[1, 1]]]]) #shape (3,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc71ce1-b7be-4c8c-be80-6d802a71b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first channel from the first sample of the input array :\n",
      " [[ 23  92  28 -51]\n",
      " [-30 -98 -69   2]\n",
      " [ 16  28   2  66]\n",
      " [ 34  74 -68  83]] \n",
      "\n",
      "maxpooling output :\n",
      " [[92. 28.]\n",
      " [74. 83.]] \n",
      "\n",
      "backward output when gradients of output with respect to maxpooling equal ones:\n",
      " [[0. 1. 1. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward, backward = maxpooling(random_array, 2, 2,comming_gradient)        \n",
    "print(f\"first channel from the first sample of the input array :\\n {random_array[0,:,:,0]} \\n\")\n",
    "print(f\"maxpooling output :\\n {forward[0,:,:,0]} \\n\")\n",
    "print(f\"backward output when gradients of output with respect to maxpooling are ones:\\n {backward[0,:,:,0]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493e3de-c8f7-4a07-9646-2d8103f71efd",
   "metadata": {},
   "source": [
    "# ReLU and LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4907c29-dd81-46a6-85bd-1efc26984f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(array, comming_gradients):        \n",
    "    # forward\n",
    "    output = np.maximum(0, array)\n",
    "    \n",
    "    # backward\n",
    "    temp = np.where(array <= 0, 0, 1)\n",
    "    gradients = np.multiply(temp, comming_gradients)\n",
    "    \n",
    "    return output, gradients\n",
    "        \n",
    "\n",
    "def LeakyReLU(array,alpha,comming_gradients):        \n",
    "    # forward\n",
    "    output = np.maximum(alpha*array, array)\n",
    "    \n",
    "    # backward\n",
    "    temp = np.ones(array.shape) #slop when x>0\n",
    "    temp[ array <= 0 ] = alpha  #slop when x<=0\n",
    "    gradients = np.multiply(temp, comming_gradients)\n",
    "    \n",
    "    return output, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1870571-8263-4e96-9eea-4fa6be6b1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.array([[[[23, 95],[92, 43],[28,  2],[-51, 89]],\n",
    "                          [[-30, 95],[-98, 77],[-69, 42],[ 2,  6]],\n",
    "                          [[16, -75],[28, 11],[ 2, 86],[66, 17]],\n",
    "                          [[34, 22],[74, 26],[-68, 38],[83,  8]]],\n",
    "                         \n",
    "                         [[[83, 95],[15, 28],[-60, 47],[42, 43]],\n",
    "                          [[73, -94],[70, 44],[-34, 56],[42, -29]],\n",
    "                          [[54, 75],[82, 35],[25, 78],[77, -43]],\n",
    "                          [[ -2, 82],[19, 16],[44, 21],[67, 33]]],\n",
    "                         \n",
    "                         [[[67, -32],[ -4, 60],[70,  8],[-48, 57]],\n",
    "                          [[ 3, 91],[33,  1],[53, 65],[17, 92]],\n",
    "                          [[22, 60],[91, 57],[-86, 87],[-42, 35]],\n",
    "                          [[56, 57],[20, 80],[90, -34],[99, 91]]]]) #shape (3,4,4,2)\n",
    "comming_gradients = np.ones_like(random_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd952560-39c2-422a-a96e-4c75204aa60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first channel from the first sample of the input array :\n",
      " [[ 23  92  28 -51]\n",
      " [-30 -98 -69   2]\n",
      " [ 16  28   2  66]\n",
      " [ 34  74 -68  83]] \n",
      "\n",
      "ReLU output :\n",
      " [[23 92 28  0]\n",
      " [ 0  0  0  2]\n",
      " [16 28  2 66]\n",
      " [34 74  0 83]] \n",
      "\n",
      "ReLU backward output when gradients of output with respect to it are ones:\n",
      " [[1 1 1 0]\n",
      " [0 0 0 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 1]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward,backward= ReLU(random_array, comming_gradients)\n",
    "print(f\"first channel from the first sample of the input array :\\n {random_array[0,:,:,0]} \\n\")\n",
    "print(f\"ReLU output :\\n {forward[0,:,:,0]} \\n\")\n",
    "print(f\"ReLU backward output when gradients of output with respect to it are ones:\\n {backward[0,:,:,0]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2318a415-e55d-42d7-b270-6986ef679419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first channel from the first sample of the input array :\n",
      " [[ 23  92  28 -51]\n",
      " [-30 -98 -69   2]\n",
      " [ 16  28   2  66]\n",
      " [ 34  74 -68  83]] \n",
      "\n",
      "LeakyReLU output :\n",
      " [[ 2.3e+01  9.2e+01  2.8e+01 -5.1e-02]\n",
      " [-3.0e-02 -9.8e-02 -6.9e-02  2.0e+00]\n",
      " [ 1.6e+01  2.8e+01  2.0e+00  6.6e+01]\n",
      " [ 3.4e+01  7.4e+01 -6.8e-02  8.3e+01]] \n",
      "\n",
      "LeakyReLU backward output when gradients of output with respect to it are ones:\n",
      " [[1.    1.    1.    0.001]\n",
      " [0.001 0.001 0.001 1.   ]\n",
      " [1.    1.    1.    1.   ]\n",
      " [1.    1.    0.001 1.   ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward,backward= LeakyReLU(random_array,0.001, comming_gradients)\n",
    "print(f\"first channel from the first sample of the input array :\\n {random_array[0,:,:,0]} \\n\")\n",
    "print(f\"LeakyReLU output :\\n {forward[0,:,:,0]} \\n\")\n",
    "print(f\"LeakyReLU backward output when gradients of output with respect to it are ones:\\n {backward[0,:,:,0]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10765cc5-b329-405f-89fd-92c232bdb6a6",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8443b087-be40-483f-bb2f-a51a5424b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(random_array,kernel,stride=1):\n",
    "    b, ih, iw, ci = random_array.shape\n",
    "    k, kh, kw, ck = kernel.shape\n",
    "    outh = int((ih-kh)/stride) + 1\n",
    "    outw = int((iw-kw)/stride) + 1\n",
    "    out = np.zeros((b, outh, outw, k))\n",
    "    \n",
    "    for ker in range (k):\n",
    "        for i in range (outh):\n",
    "            hst = i*stride\n",
    "            hend = hst + kh\n",
    "            \n",
    "            for j in range (outw):\n",
    "                vst = j*stride\n",
    "                vend = vst + kw\n",
    "            \n",
    "                temp = random_array[:, hst:hend, vst:vend, :]\n",
    "                temp = kernel[ker,:,:,:]*temp\n",
    "                out[:,i,j,ker] = np.sum(temp,axis=(1,2,3))\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67661830-8999-42ed-94df-732eac097757",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.array([[[[23, 95],[92, 43],[28,  2],[51, 89]],\n",
    "                         [[30, 95],[98, 77],[69, 42],[ 2,  6]],\n",
    "                         [[16, 75],[28, 11],[ 2, 86],[66, 17]],\n",
    "                         [[34, 22],[74, 26],[68, 38],[83,  8]]],\n",
    "                        \n",
    "                        [[[83, 95],[15, 28],[60, 47],[42, 43]],\n",
    "                         [[73, 94],[70, 44],[34, 56],[42, 29]],\n",
    "                         [[54, 75],[82, 35],[25, 78],[77, 43]],\n",
    "                         [[ 2, 82],[19, 16],[44, 21],[67, 33]]],\n",
    "                        \n",
    "                        [[[67, 32],[ 4, 60],[70,  8],[48, 57]],\n",
    "                         [[ 3, 91],[33,  1],[53, 65],[17, 92]],\n",
    "                         [[22, 60],[91, 57],[86, 87],[42, 35]],\n",
    "                         [[56, 57],[20, 80],[90, 34],[99, 91]]]]) #shape (3,4,4,2)\n",
    "\n",
    "kernel = np.array([[[[0, 1],[1, 1]],\n",
    "                    [[0, 1],[0, 0]]],\n",
    "                   [[[1, 0],[1, 1]],\n",
    "                    [[0, 1],[1, 1]]]]) #shape (2,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29339d1a-f716-4c21-9a18-e6b85acbdbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input array:\n",
      "first channel: \n",
      "[[23 92 28 51]\n",
      " [30 98 69  2]\n",
      " [16 28  2 66]\n",
      " [34 74 68 83]] \n",
      "\n",
      "second channel: \n",
      "[[95 43  2 89]\n",
      " [95 77 42  6]\n",
      " [75 11 86 17]\n",
      " [22 26 38  8]] \n",
      "\n",
      "kernel :\n",
      "first channel: \n",
      "[[0 1]\n",
      " [0 0]] \n",
      "\n",
      "second channel: \n",
      "[[1 1]\n",
      " [1 0]] \n",
      "\n",
      "first output: \n",
      "[[325. 150. 184.]\n",
      " [345. 199. 136.]\n",
      " [136. 125. 207.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = convolution(random_array, kernel)\n",
    "print(f\"input array:\\nfirst channel: \\n{random_array[0,:,:,0]} \\n\")\n",
    "print(f\"second channel: \\n{random_array[0,:,:,1]} \\n\")\n",
    "\n",
    "print(f\"kernel :\\nfirst channel: \\n{kernel[0,:,:,0]} \\n\")\n",
    "print(f\"second channel: \\n{kernel[0,:,:,1]} \\n\")\n",
    "\n",
    "print(f\"first output: \\n{output[0,:,:,0]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c245b6-8d28-4bbc-90be-a6641e1073ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self):\n",
    "    X = self.inputs[0]\n",
    "    kernels, biases = self.parameters\n",
    "\n",
    "    # Initialize gradients\n",
    "    self.gradients[kernels] = np.zeros_like(kernels.value)\n",
    "    self.gradients[biases] = np.zeros_like(biases.value)\n",
    "    self.gradients[X] = np.zeros_like(X.value)\n",
    "\n",
    "    dL_dOutput = self.outputs[0].gradients[self]  # Gradient of loss w.r.t output\n",
    "\n",
    "    # Compute gradients w.r.t. kernels and biases\n",
    "    for b in range(self.batch_size):\n",
    "        for k in range(self.number_of_kernals):\n",
    "            for i in range(dL_dOutput.shape[1]):  # Iterate over output height\n",
    "                h_start = i * self.stride\n",
    "                h_end = h_start + self.kernal_HW\n",
    "\n",
    "                for j in range(dL_dOutput.shape[2]):  # Iterate over output width\n",
    "                    w_start = j * self.stride\n",
    "                    w_end = w_start + self.kernal_HW\n",
    "\n",
    "                    # Slice the input window\n",
    "                    input_window = X.value[b, h_start:h_end, w_start:w_end, :]\n",
    "\n",
    "                    # Update gradient w.r.t. kernels\n",
    "                    self.gradients[kernels][k] += input_window * dL_dOutput[b, i, j, k]\n",
    "\n",
    "                    # Update gradient w.r.t. input\n",
    "                    self.gradients[X][b, h_start:h_end, w_start:w_end, :] += (\n",
    "                        kernels.value[k] * dL_dOutput[b, i, j, k]\n",
    "                    )\n",
    "\n",
    "            # Update gradient w.r.t. biases (sum over spatial dimensions)\n",
    "            self.gradients[biases][k] += np.sum(dL_dOutput[b, :, :, k])\n",
    "\n",
    "    # Backward propagate gradients to kernels and biases\n",
    "    kernels.backward()\n",
    "    biases.backward()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
